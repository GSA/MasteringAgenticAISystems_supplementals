# Part_04 - YouTube Video Resources

This document aggregates all YouTube video resources for every chapter in this part.

---

## Unknown Chapter

### Video 1: Kubernetes Tutorial for Beginners

---

### Video 2: Kubernetes Crash Course for Absolute Beginners

---

### Video 3: Docker and Kubernetes - Full Course for Beginners (6 Hours)

---

### Video 4: Docker Tutorial for Beginners (3 Hours)

---

### Video 5: Microservices Architecture Tutorial for Beginners (4 Hours)

---

### Video 6: Deploy with Docker - Step-by-Step Tutorial

---

### Video 7: Auto Scaling and Load Balancing Explained

---

### Video 8: TensorRT-LLM for LLM Inference Optimization

---

## 4.1 - AI Agent Deployment and Scaling

### Video 1: Kafka vs RabbitMQ Comparison

**URL:** [https://www.datacamp.com/blog/kafka-vs-rabbitmq](https://www.datacamp.com/blog/kafka-vs-rabbitmq)

**Channel:** DataCamp

**Duration:** Educational blog with embedded resources

---

### Video 2: Vector Databases for RAG - Pinecone

**URL:** [https://www.pinecone.io/learn/retrieval-augmented-generation/](https://www.pinecone.io/learn/retrieval-augmented-generation/)

**Channel:** Pinecone (Educational Content)

**Duration:** Tutorial series

---

### Video 3: Vector Database Comparison (Multiple Solutions)

**URL:** [https://research.aimultiple.com/vector-database-for-rag/](https://research.aimultiple.com/vector-database-for-rag/)

**Channel:** AI Multiple (Research & Education)

**Duration:** Comprehensive guide

---

### Video 4: Prometheus and Grafana Observability Stack

**URL:** [https://grafana.com/docs/grafana/latest/fundamentals/getting-started/first-dashboards/get-started-grafana-prometheus/](https://grafana.com/docs/grafana/latest/fundamentals/getting-started/first-dashboards/get-started-grafana-prometheus/)

**Channel:** Grafana Official Documentation

**Duration:** Comprehensive tutorial

---

### Video 5: MLOps - Continuous Delivery and Automation Pipelines

**URL:** [https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

**Channel:** Google Cloud Architecture Center

**Duration:** Comprehensive guide

---

### Video 6: MLOps by Creating a YouTube Sentiment Analyzer

**URL:** [https://www.freecodecamp.org/news/learn-mlops-by-creating-a-youtube-sentiment-analyzer/](https://www.freecodecamp.org/news/learn-mlops-by-creating-a-youtube-sentiment-analyzer/)

**Channel:** freeCodeCamp (YouTube)

**Duration:** ~3 hours

---

### Video 7: CI/CD Pipeline with Docker and Kubernetes

**URL:** [https://medium.com/@ucheblessed/ci-cd-with-docker-and-kubernetes-deploying-containerized-applications-7556f0727517](https://medium.com/@ucheblessed/ci-cd-with-docker-and-kubernetes-deploying-containerized-applications-7556f0727517)

**Channel:** Medium (Technical Tutorial)

**Duration:** Tutorial article with code examples

---

### Video 8: Microservices Architecture and Distributed Systems

**URL:** [https://www.classcentral.com/course/youtube-microservices-architecture-patterns-53291](https://www.classcentral.com/course/youtube-microservices-architecture-patterns-53291)

**Channel:** Class Central (YouTube Aggregator)

**Duration:** ~6 hours comprehensive course

---

## 4.2 - Deployment & Scaling for Agentic Systems

### Video 1: Microservices Architecture Fundamentals

**URL:** [https://www.classcentral.com/course/youtube-microservices-architecture-microservices-for-beginner-53296](https://www.classcentral.com/course/youtube-microservices-architecture-microservices-for-beginner-53296)

**Channel:** Edureka / Class Central Curated

**Duration:** ~6 hours

**Relevance:** Directly covers Chapter 4.2's microservices deployment pattern section with comprehensive coverage of service decomposition, API communication, and fault tolerance

---

### Video 2: Distributed Systems & System Design

**URL:** [https://www.classcentral.com/course/youtube-distributed-systems-93086](https://www.classcentral.com/course/youtube-distributed-systems-93086)

**Channel:** Hussein Nasser

**Duration:** ~4.5 hours

**Relevance:** Provides foundational understanding of distributed architectures that enable microservices scaling and fault tolerance patterns discussed in Chapter 4.2

---

### Video 3: RabbitMQ vs Kafka: Message Queue Comparison

**URL:** [https://www.cloudamqp.com/blog/when-to-use-rabbitmq-or-apache-kafka.html](https://www.cloudamqp.com/blog/when-to-use-rabbitmq-or-apache-kafka.html)

**Channel:** CloudAMQP / Educational Resources

**Duration:** Article + reference materials

**Relevance:** Directly addresses Chapter 4.2's detailed message queue comparison section with technical guidance on RabbitMQ vs Kafka architectural choices for multi-agent systems

---

### Video 4: Vector Databases for AI & RAG Systems

**URL:** [https://www.pinecone.io/](https://www.pinecone.io/)

**Channel:** Pinecone Educational Resources

**Duration:** Multiple tutorials and documentation

**Relevance:** Covers vector database fundamentals and Pinecone-specific implementation, directly supporting Chapter 4.2's section on vector databases for agent memory and retrieval-augmented generation

---

### Video 5: Prometheus & Grafana Observability Stack

**URL:** [https://www.udemy.com/course/prometheus-and-grafana-learn-monitoring-alerting-today/](https://www.udemy.com/course/prometheus-and-grafana-learn-monitoring-alerting-today/)

**Channel:** Udemy Instructor

**Duration:** ~15 hours

**Relevance:** Comprehensive coverage of observability infrastructure fundamentals in Chapter 4.2, including LLM-specific metrics, alerting, and dashboard design for distributed agent systems

---

### Video 6: API Gateway Architecture - Kong & NGINX

**URL:** [https://docs.konghq.com/gateway/latest/get-started/rate-limiting/](https://docs.konghq.com/gateway/latest/get-started/rate-limiting/)

**Channel:** Kong Gateway Official Documentation

**Duration:** Multiple tutorials and guides

**Relevance:** Detailed coverage of API gateway pattern from Chapter 4.2, with specific focus on Kong's sophisticated features for policy enforcement and request routing in multi-agent systems

---

### Video 7: MLOps & CI/CD for Machine Learning

**URL:** [https://www.udemy.com/course/devops-to-mlops-bootcamp/](https://www.udemy.com/course/devops-to-mlops-bootcamp/)

**Channel:** Udemy DevOps/MLOps Instructor

**Duration:** ~20 hours

**Relevance:** Comprehensive MLOps lifecycle coverage from Chapter 4.2, including component versioning for agents, behavioral testing, quality evaluation, and progressive deployment strategies

---

### Video 8: Canary Deployments & Progressive Rollouts

**URL:** [https://www.harness.io/blog/blue-green-canary-deployment-strategies](https://www.harness.io/blog/blue-green-canary-deployment-strategies)

**Channel:** Harness Educational Resources

**Duration:** Blog post + reference materials + embedded videos

**Relevance:** Directly covers Chapter 4.2's progressive deployment and canary rollout strategies for minimizing production risk while enabling rapid iteration

---

### Video 9: Google Cloud MLOps Architecture

**URL:** [https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

**Channel:** Google Cloud Documentation

**Duration:** ~3 hours

**Relevance:** Enterprise-scale MLOps implementation covering CI/CD pipeline stages, containerization, artifact management, and progressive deployment patterns from Chapter 4.2

---

### Video 10: DeepLearning.AI MLOps & Deployment

**URL:** [https://www.deeplearning.ai/](https://www.deeplearning.ai/)

**Channel:** DeepLearning.AI

**Duration:** Multiple courses available

**Relevance:** Specialized content on agentic AI systems deployment, directly supporting Chapter 4.2's distinction between traditional MLOps and agentic MLOps with multiple component versioning

---

## Part 4.3 - Container Orchestration and Edge Deployment

### Video 1: Building and Running Agentic AI Platforms on Kubernetes

**URL:** [https://www.classcentral.com/course/youtube-building-and-running-agentic-ai-platforms-on-kubernetes-490694](https://www.classcentral.com/course/youtube-building-and-running-agentic-ai-platforms-on-kubernetes-490694)

**Channel:** freeCodeCamp / Platform Engineering

**Duration:** ~44 minutes (webinar)

**Covers:** Kubernetes for AI workloads, container orchestration, agentic AI deployment, production Kubernetes patterns, service mesh concepts

---

### Video 2: Kubernetes Course - Full Beginners Tutorial

**URL:** [https://www.classcentral.com/course/freecodecamp-kubernetes-course-full-beginners-tutorial-containerize-your-apps-104877](https://www.classcentral.com/course/freecodecamp-kubernetes-course-full-beginners-tutorial-containerize-your-apps-104877)

**Channel:** freeCodeCamp

**Duration:** Full comprehensive course

**Covers:** Kubernetes fundamentals, deployments, services, resource specifications, pod creation, YAML configuration, scaling basics

---

### Video 3: Istio Setup in Kubernetes - Step by Step Guide

**URL:** [https://www.classcentral.com/course/youtube-istio-setup-in-kubernetes-step-by-step-guide-to-install-istio-service-mesh-108864](https://www.classcentral.com/course/youtube-istio-setup-in-kubernetes-step-by-step-guide-to-install-istio-service-mesh-108864)

**Channel:** TechWorld with Nana

**Duration:** ~27 minutes

**Covers:** Service mesh concepts, Istio installation, Envoy proxy injection, traffic management, mTLS, authorization policies, Kiali monitoring

---

### Video 4: Docker and Kubernetes - Full Course for Beginners

**URL:** [https://www.classcentral.com/course/freecodecamp-docker-and-kubernetes-full-course-for-beginners-57815](https://www.classcentral.com/course/freecodecamp-docker-and-kubernetes-full-course-for-beginners-57815)

**Channel:** freeCodeCamp

**Duration:** Full comprehensive course

**Covers:** Container basics, Kubernetes cluster architecture, deployments, stateless vs stateful applications, scaling strategies

---

### Video 5: A Visual Guide to Quantization (Model Optimization)

**URL:** [https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)

**Channel:** Maarten Grootendorst (Educational content)

**Duration:** Article with visual explanations and diagrams

**Covers:** INT8 quantization, model compression, precision reduction, symmetric and asymmetric quantization, edge optimization

---

### Video 6: Getting Started with Edge AI on NVIDIA Jetson

**URL:** [https://developer.nvidia.com/blog/getting-started-with-edge-ai-on-nvidia-jetson-llms-vlms-and-foundation-models-for-robotics/](https://developer.nvidia.com/blog/getting-started-with-edge-ai-on-nvidia-jetson-llms-vlms-and-foundation-models-for-robotics/)

**Channel:** NVIDIA Technical Blog (includes video resources)

**Duration:** Multiple tutorials, varies

**Covers:** NVIDIA Jetson hardware platform, edge AI deployment, LLM inference on edge, optimization strategies, real-time decision making

---

### Video 7: NVIDIA Jetson Tutorials Portal

**URL:** [https://developer.nvidia.com/embedded/learn/tutorials](https://developer.nvidia.com/embedded/learn/tutorials)

**Channel:** NVIDIA Developer

**Duration:** Multiple tutorial videos, 5-30 minutes each

**Covers:** Jetson setup, inference optimization, TensorRT usage, computer vision on edge, real-time AI applications

---

### Video 8: Knowledge Distillation Tutorial - PyTorch

**URL:** [https://docs.pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html](https://docs.pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html)

**Channel:** PyTorch Official Documentation

**Duration:** Tutorial with code examples

**Covers:** Knowledge distillation technique, model compression, student-teacher training, edge model optimization

---

## 4.5 - NVIDIA NIM and Triton Inference Server - Study Outcomes

### Video 1: Accelerated LLM Inference with Anyscale - Ray Summit 2024

**URL:** [https://www.classcentral.com/course/youtube-accelerated-llm-inference-with-anyscale-ray-summit-2024-353703](https://www.classcentral.com/course/youtube-accelerated-llm-inference-with-anyscale-ray-summit-2024-353703)

**Channel:** Class Central / Anyscale

**Duration:** ~30 minutes

**Covers:** vLLM continuous batching, FP8 support, inference optimization techniques, production LLM deployment patterns, speculative decoding, chunked prefill, multi-step decoding

---

### Video 2: The Evolution of Multi-GPU Inference in vLLM - Ray Summit 2024

**URL:** [https://www.classcentral.com/course/youtube-the-evolution-of-multi-gpu-inference-in-vllm-ray-summit-2024-355168](https://www.classcentral.com/course/youtube-the-evolution-of-multi-gpu-inference-in-vllm-ray-summit-2024-355168)

**Channel:** Class Central / Anyscale

**Duration:** ~25 minutes (approx)

**Covers:** Tensor parallelism, multi-GPU distributed inference, vLLM architecture, throughput optimization, GPU utilization improvements

---

### Video 3: Optimizing vLLM Performance Through Quantization - Ray Summit 2024

**URL:** [https://www.classcentral.com/course/youtube-optimizing-vllm-performance-through-quantization-ray-summit-2024-355165](https://www.classcentral.com/course/youtube-optimizing-vllm-performance-through-quantization-ray-summit-2024-355165)

**Channel:** Class Central / Anyscale

**Duration:** ~20 minutes (approx)

**Covers:** FP8 quantization, INT8 compression, model optimization for inference, throughput improvements, accuracy preservation during quantization

---

### Video 4: The State of vLLM - Ray Summit 2024

**URL:** [https://www.classcentral.com/course/youtube-the-state-of-vllm-ray-summit-2024-353701](https://www.classcentral.com/course/youtube-the-state-of-vllm-ray-summit-2024-353701)

**Channel:** Class Central / Anyscale (speakers: Kuntai Du, UC Chicago & Zhuohan Li, UC Berkeley)

**Duration:** ~35 minutes

**Covers:** vLLM architecture and advancements, continuous batching mechanisms, inference optimization, production deployment patterns, recent improvements in LLM serving

---

### Video 5: Inference with Torch-TensorRT - Deep Learning Prediction Optimization

**URL:** [https://www.classcentral.com/course/youtube-inference-with-torch-tensorrt-deep-learning-prediction-for-beginners-cpu-vs-cuda-vs-tensorrt-117106](https://www.classcentral.com/course/youtube-inference-with-torch-tensorrt-deep-learning-prediction-for-beginners-cpu-vs-cuda-vs-tensorrt-117106)

**Channel:** Class Central

**Duration:** ~25-30 minutes (approx)

**Covers:** TensorRT optimization fundamentals, kernel auto-tuning, CUDA acceleration, layer fusion, precision calibration, CPU vs GPU vs TensorRT performance comparisons, inference speedups (40x claims)

---

### Video 6: Databricks vLLM Optimization for Cost-Effective LLM Inference - Ray Summit 2024

**URL:** [https://www.classcentral.com/course/youtube-databricks-vllm-optimization-for-cost-effective-llm-inference-ray-summit-2024-353688](https://www.classcentral.com/course/youtube-databricks-vllm-optimization-for-cost-effective-llm-inference-ray-summit-2024-353688)

**Channel:** Class Central / Databricks / Anyscale

**Duration:** ~25 minutes (approx)

**Covers:** vLLM production optimization, cost-effective inference deployment, performance tuning, practical deployment strategies, integration with production systems

---

### Video 7: Optimizing vLLM for Intel CPUs and XPUs - Ray Summit 2024

**URL:** [https://www.classcentral.com/course/youtube-optimizing-vllm-for-intel-cpus-and-xpus-ray-summit-2024-353690](https://www.classcentral.com/course/youtube-optimizing-vllm-for-intel-cpus-and-xpus-ray-summit-2024-353690)

**Channel:** Class Central / Anyscale (speakers: Ding Ke & Yuan Zhou)

**Duration:** ~30 minutes (approx)

**Covers:** Hardware-specific optimization, CPU acceleration, cross-platform inference, performance considerations for different hardware architectures

---

### Video 8: Intelligent Data Classification with Ray and vLLM at Apple - Ray Summit 2024

**URL:** [https://www.classcentral.com/course/youtube-intelligent-data-classification-with-ray-and-vllm-at-apple-ray-summit-2024-355169](https://www.classcentral.com/course/youtube-intelligent-data-classification-with-ray-and-vllm-at-apple-ray-summit-2024-355169)

**Channel:** Class Central / Anyscale (Apple case study)

**Duration:** ~25 minutes (approx)

**Covers:** Enterprise LLM deployment, production inference pipelines, model ensemble patterns, real-world production considerations, scaling strategies

---

## Unknown Chapter

### Video 1: Speeding up LLM Inference With TensorRT-LLM (GTC 2024 S62031)

**URL:** [https://www.nvidia.com/en-us/on-demand/session/gtc24-s62031/](https://www.nvidia.com/en-us/on-demand/session/gtc24-s62031/)

**Channel:** NVIDIA GTC (GPU Technology Conference)

**Duration:** ~40-50 minutes (typical for GTC sessions)

**Covers:** TensorRT-LLM optimization pipeline, precision reduction, kernel fusion, performance benchmarking, production deployment strategies

---

### Video 2: Optimize Generative AI Inference with Quantization in TensorRT-LLM and TensorRT (GTC 24 S63213)

**URL:** [https://www.nvidia.com/en-us/on-demand/session/gtc24-s63213/](https://www.nvidia.com/en-us/on-demand/session/gtc24-s63213/)

**Channel:** NVIDIA GTC (GPU Technology Conference)

**Duration:** ~40-50 minutes

**Covers:** INT8 quantization, entropy calibration, QAT (Quantization Aware Training), calibration dataset requirements, accuracy-performance tradeoffs, precision modes (per-tensor, per-channel, per-token)

---

### Video 3: Quantization Fundamentals with Hugging Face (DeepLearning.AI Course)

**URL:** [https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/](https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/)

**Channel:** DeepLearning.AI (instructors: Younes Belkada and Marc Sun from Hugging Face)

**Duration:** ~1-2 hours total course (structured in modules)

**Covers:** Linear quantization techniques, INT8 calibration, post-training quantization (PTQ), quantization-aware training (QAT), practical quantization implementation with HuggingFace Quanto library, model compression strategies

---

### Video 4: The Evolution of Multi-GPU Inference in vLLM (Ray Summit 2024 - Anyscale)

**URL:** [https://www.classcentral.com/course/youtube-the-evolution-of-multi-gpu-inference-in-vllm-ray-summit-2024-355168](https://www.classcentral.com/course/youtube-the-evolution-of-multi-gpu-inference-in-vllm-ray-summit-2024-355168)

**Channel:** Anyscale / Ray Summit 2024

**Duration:** ~30-40 minutes

**Covers:** Distributed GPU inference, tensor parallelism, pipeline parallelism, expert parallelism, multi-GPU optimization strategies, vLLM architecture for distributed serving, scaling inference across multiple GPUs

---

### Video 5: Accelerated LLM Inference with Anyscale (Ray Summit 2024)

**URL:** [https://www.classcentral.com/course/youtube-accelerated-llm-inference-with-anyscale-ray-summit-2024-353703](https://www.classcentral.com/course/youtube-accelerated-llm-inference-with-anyscale-ray-summit-2024-353703)

**Channel:** Anyscale / Ray Summit 2024 (speakers: Philipp Moritz, Cody Yu)

**Duration:** ~30 minutes

**Covers:** LLM inference optimization techniques, FP8 support, chunked prefill, multi-step decoding, speculative decoding, throughput and latency improvements, production serving strategies

---

### Video 6: Databricks' vLLM Optimization for Cost-Effective LLM Inference (Ray Summit 2024)

**URL:** [https://www.classcentral.com/course/youtube-databricks-vllm-optimization-for-cost-effective-llm-inference-ray-summit-2024-353688](https://www.classcentral.com/course/youtube-databricks-vllm-optimization-for-cost-effective-llm-inference-ray-summit-2024-353688)

**Channel:** Databricks / Ray Summit 2024

**Duration:** ~25-30 minutes

**Covers:** GPU blocking operations during decoding, inference optimization reducing GPU idle time, batching strategies, KV cache optimization, cost-effective serving patterns

---

### Video 7: Optimize TensorFlow Models For Deployment with TensorRT (Coursera Guided Project)

**URL:** [https://www.coursera.org/projects/tensorflow-tensorrt](https://www.coursera.org/projects/tensorflow-tensorrt)

**Channel:** Coursera / DeepLearning.AI

**Duration:** ~2 hours (hands-on guided project)

**Covers:** TensorRT integration with TensorFlow, FP32/FP16/INT8 precision optimization, TensorRT parameter tuning, performance measurement, inference throughput optimization

---

### Video 8: Building Modern Distributed Systems with Raft Consensus

**URL:** [https://www.oreilly.com/library/view/building-modern-distributed/9781804613313/video4_2.html](https://www.oreilly.com/library/view/building-modern-distributed/9781804613313/video4_2.html)

**Channel:** O'Reilly Media (RAFT Consensus Algorithm video)

**Duration:** Video course module (typically 10-20 minutes)

**Covers:** Raft consensus algorithm, distributed consensus for high availability, leader election, state machine replication, fault tolerance in distributed systems

---

## 4.7 - Scaling Strategies for AI Agent Systems

### Video 1: EP47: Common Load-balancing Algorithms

**URL:** [https://blog.bytebytego.com/p/ep47-common-load-balancing-algorithms](https://blog.bytebytego.com/p/ep47-common-load-balancing-algorithms)

**Channel:** ByteByteGo

**Duration:** ~15-20 minutes (article + visual explanations)

**Covers:** Round robin, least connections, weighted round robin, IP hash, load balancing algorithms

---

### Video 2: A Crash Course on Load Balancers for Scaling

**URL:** [https://blog.bytebytego.com/p/a-crash-course-on-load-balancers](https://blog.bytebytego.com/p/a-crash-course-on-load-balancers)

**Channel:** ByteByteGo

**Duration:** ~12-15 minutes (article + visuals)

**Covers:** Load balancer fundamentals, scaling, traffic distribution, Kubernetes Service

---

### Video 3: Accelerating LLM Inference with vLLM (Databricks)

**URL:** [https://www.classcentral.com/course/youtube-accelerating-llm-inference-with-vllm-306334](https://www.classcentral.com/course/youtube-accelerating-llm-inference-with-vllm-306334)

**Channel:** Databricks/Ray Summit 2024

**Duration:** ~36 minutes

**Covers:** Continuous batching, paged attention, GPU optimization, LLM inference optimization

---

### Video 4: Databricks' vLLM Optimization for Cost-Effective LLM Inference (Ray Summit 2024)

**URL:** [https://www.classcentral.com/course/youtube-databricks-vllm-optimization-for-cost-effective-llm-inference-ray-summit-2024-353688](https://www.classcentral.com/course/youtube-databricks-vllm-optimization-for-cost-effective-llm-inference-ray-summit-2024-353688)

**Channel:** Anyscale/Ray Summit 2024

**Duration:** ~25 minutes

**Covers:** Cost-effective inference, GPU blocking, decoding optimization, throughput improvement

---

### Video 5: Backend Engineering - Intermediate (Hussein Nasser)

**URL:** [https://www.classcentral.com/course/youtube-backend-engineering-intermediate-93094](https://www.classcentral.com/course/youtube-backend-engineering-intermediate-93094)

**Channel:** Hussein Nasser

**Duration:** Multi-part course (estimated 4-6 hours total)

**Covers:** Connection management, load balancing, database sharding, scaling challenges

---

### Video 6: Backend Engineering - Advanced (Hussein Nasser)

**URL:** [https://www.classcentral.com/course/youtube-backend-engineering-advanced-93095](https://www.classcentral.com/course/youtube-backend-engineering-advanced-93095)

**Channel:** Hussein Nasser

**Duration:** Multi-part course (estimated 4-6 hours total)

**Covers:** Advanced scaling, auto-scaling, cost optimization, high-availability

---

### Video 7: System Designs (Hussein Nasser)

**URL:** [https://www.classcentral.com/course/youtube-system-designs-93083](https://www.classcentral.com/course/youtube-system-designs-93083)

**Channel:** Hussein Nasser

**Duration:** Multi-part course (estimated 3-5 hours total)

**Covers:** Scalable system design, caching, redundancy, load balancing

---

### Video 8: Kubernetes Autoscaling - HPA/VPA/Cluster Autoscaler

**URL:** [https://www.kubecost.com/kubernetes-autoscaling/kubernetes-hpa/](https://www.kubecost.com/kubernetes-autoscaling/kubernetes-hpa/)

**Channel:** Kubecost/Kubernetes Community

**Duration:** Multi-part tutorial (estimated 2-3 hours total)

**Covers:** Horizontal Pod Autoscaler (HPA), Vertical Pod Autoscaler (VPA), metrics, policies

---


## Summary

- **Total Chapters:** 8
- **Total Videos:** 58
- **Research Date:** 2026-02-02
