# Part 03: Deploying Agentic AI - YouTube Video Resources

## Table of Contents

- [Chapter 3.1A - Hallucination Detection](#chapter-31a---hallucination-detection)
- [Chapter 3.1B - Grounding in External Knowledge](#chapter-31b---grounding-in-external-knowledge)
- [Chapter 3.1C - Multi-Modal Evaluation](#chapter-31c---multi-modal-evaluation)
- [Chapter 3.2 - Context Relevance](#chapter-32---context-relevance)
- [Chapter 3.3 - Harmfulness & Safety Assessment](#chapter-33---harmfulness--safety-assessment)
- [Chapter 3.4 - Behavioral Consistency](#chapter-34---behavioral-consistency)
- [Chapter 3.5 - Prompt Optimization, Few-Shot Learning, and Fine-Tuning](#chapter-35---prompt-optimization-few-shot-learning-and-fine-tuning)
- [Chapter 3.6 - Agent Benchmarking Frameworks](#chapter-36---agent-benchmarking-frameworks)
- [Chapter 3.7 - Tool Auditing](#chapter-37---tool-auditing)
- [Chapter 3.8 - Action Accuracy](#chapter-38---action-accuracy)
- [Chapter 3.9 - Reasoning Quality](#chapter-39---reasoning-quality)
- [Chapter 3.10 - Efficiency Metrics](#chapter-310---efficiency-metrics)

---

<a name="chapter-31a---hallucination-detection"></a>
## Chapter 3.1A - Hallucination Detection

**Topics:** Factual consistency, response grounding, factual overlap, knowledge verification, semantic similarity metrics

### Detecting Hallucinations in Large Language Models Using Semantic Entropy
- [https://www.youtube.com/watch?v=15I5rna-gag](https://www.youtube.com/watch?v=15I5rna-gag) ~30 minutes
- Covers: Semantic entropy as a hallucination detection technique, factual consistency verification without ground truth, theoretical foundations of semantic uncertainty, practical applications in detecting confabulations

### Do Androids Know They're Only Dreaming of Electric Sheep? - Hallucination Detection Paper Review
- [https://www.youtube.com/watch?v=YkLRGl8wZTM](https://www.youtube.com/watch?v=YkLRGl8wZTM) ~45 minutes
- Covers: Self-consistency checking approaches, probability-based hallucination detection, model awareness of factual uncertainty, internal vs external validation methods

### Introduction to RAG (Retrieval-Augmented Generation) | LlamaIndex
- [https://www.youtube.com/watch?v=A4U5CwcXr0I](https://www.youtube.com/watch?v=A4U5CwcXr0I) ~15 minutes
- Covers: RAG fundamentals for grounding LLM outputs, retrieval mechanisms to reduce hallucinations, grounding strategies using external knowledge, integration with LLM workflows

---

<a name="chapter-31b---grounding-in-external-knowledge"></a>
## Chapter 3.1B - Grounding in External Knowledge

**Topics:** RAG systems, knowledge graphs, claim verification, entity linking, grounding pipelines

### RAG from Scratch - Complete Course
- [https://www.youtube.com/watch?v=sVcwVQRHIc8](https://www.youtube.com/watch?v=sVcwVQRHIc8) ~1 hour
- Covers: RAG fundamentals and architecture, document chunking and embedding strategies, retrieval mechanisms and ranking, integration with LLM workflows

### Advanced RAG Techniques - Greg Kamradt
- [https://www.youtube.com/watch?v=TRjq7t2Ms5I](https://www.youtube.com/watch?v=TRjq7t2Ms5I) ~45 minutes
- Covers: Query transformation strategies, routing and retrieval optimization, multi-query generation, HyDE (Hypothetical Document Embeddings)

### Build a Knowledge Graph with LLMs
- [https://www.youtube.com/watch?v=qks4UD7q-oE](https://www.youtube.com/watch?v=qks4UD7q-oE) ~30 minutes
- Covers: Knowledge graph construction from unstructured data, entity extraction and relationship mapping, graph-based retrieval for grounding, integration with RAG systems

### RAG++ - Advanced RAG with LlamaIndex
- [https://www.youtube.com/watch?v=vIJz4I1vjSE](https://www.youtube.com/watch?v=vIJz4I1vjSE) ~50 minutes
- Covers: Advanced indexing strategies, query engines and retrieval optimization, agent-based retrieval workflows, production RAG deployment patterns

### Entity Linking and Knowledge Graphs
- [https://www.youtube.com/watch?v=H6CgSz4q6wI](https://www.youtube.com/watch?v=H6CgSz4q6wI) ~1 hour
- Covers: Entity recognition and disambiguation, knowledge graph integration, named entity linking techniques, graph-based reasoning

### RAGAS - Evaluation Framework for RAG
- [https://www.youtube.com/watch?v=6Q-PH04F_Ow](https://www.youtube.com/watch?v=6Q-PH04F_Ow) ~25 minutes
- Covers: RAG evaluation metrics (faithfulness, relevance), automated assessment of retrieval quality, grounding accuracy measurement, production monitoring for RAG systems

### Evaluating RAG Systems - DeepLearning.AI
- [https://www.youtube.com/watch?v=pGtVWFHHqT0](https://www.youtube.com/watch?v=pGtVWFHHqT0) ~15 minutes
- Covers: Context relevance metrics, faithfulness scoring, answer relevance evaluation, best practices for RAG assessment

### Multi-Query Retrieval for Better RAG
- [https://www.youtube.com/watch?v=SuI7j-hKG-U](https://www.youtube.com/watch?v=SuI7j-hKG-U) ~20 minutes
- Covers: Query transformation techniques, multi-perspective retrieval, fusion of retrieval results, improving grounding coverage

### Corrective RAG (CRAG) Implementation
- [https://www.youtube.com/watch?v=EvlPm5iZZjc](https://www.youtube.com/watch?v=EvlPm5iZZjc) ~25 minutes
- Covers: Self-correcting retrieval mechanisms, grounding verification and correction, adaptive retrieval strategies, quality-aware document selection

### Graph RAG - Microsoft Research
- [https://www.youtube.com/watch?v=r09tJfON6kE](https://www.youtube.com/watch?v=r09tJfON6kE) ~40 minutes
- Covers: Graph-based retrieval augmentation, community detection for knowledge organization, hierarchical summarization, combining graphs with traditional RAG

### Semantic Chunking for RAG
- [https://www.youtube.com/watch?v=8OJC21T2SL4](https://www.youtube.com/watch?v=8OJC21T2SL4) ~15 minutes
- Covers: Intelligent document chunking strategies, semantic coherence in chunks, embedding-based segmentation, optimizing retrieval granularity

### Claim Verification with Knowledge Bases
- [https://www.youtube.com/watch?v=MJ1hOqEfMcU](https://www.youtube.com/watch?v=MJ1hOqEfMcU) ~50 minutes
- Covers: Automated claim verification techniques, knowledge base querying, evidence retrieval and ranking, fact-checking pipelines

---

<a name="chapter-31c---multi-modal-evaluation"></a>
## Chapter 3.1C - Multi-Modal Evaluation

**Topics:** Vision-language models, audio transcription, OCR, document understanding, cross-modal consistency

### CLIP (Contrastive Language-Image Pre-training) Explained
- [https://www.youtube.com/watch?v=T9XSU0pKX2E](https://www.youtube.com/watch?v=T9XSU0pKX2E) ~35 minutes
- Covers: Vision-language model architecture, contrastive learning for cross-modal alignment, zero-shot image classification, image-text embedding spaces

### Visual Question Answering with Vision Transformers
- [https://www.youtube.com/watch?v=5tW3y7lm7V0](https://www.youtube.com/watch?v=5tW3y7lm7V0) ~30 minutes
- Covers: VQA task formulation, vision transformer architectures, multi-modal fusion techniques, benchmark datasets and evaluation

### OCR and Document Understanding with LayoutLM
- [https://www.youtube.com/watch?v=K9nzP_vqqns](https://www.youtube.com/watch?v=K9nzP_vqqns) ~25 minutes
- Covers: Document layout understanding, text extraction and spatial reasoning, form understanding and key-value extraction, multi-modal document processing

### Whisper - Robust Speech Recognition
- [https://www.youtube.com/watch?v=ABFqbY_rmEk](https://www.youtube.com/watch?v=ABFqbY_rmEk) ~20 minutes
- Covers: Audio transcription with Whisper, multi-lingual speech recognition, robustness to noise and accents, transcription accuracy evaluation

### Vision Transformers (ViT) Explained
- [https://www.youtube.com/watch?v=TrdevFK_am4](https://www.youtube.com/watch?v=TrdevFK_am4) ~40 minutes
- Covers: Vision transformer architecture, image patch embeddings, attention mechanisms for vision, transfer learning for vision tasks

### LLaVA - Large Language and Vision Assistant
- [https://www.youtube.com/watch?v=mkI7EPD1vp8](https://www.youtube.com/watch?v=mkI7EPD1vp8) ~30 minutes
- Covers: Multi-modal instruction following, vision-language alignment, visual reasoning capabilities, evaluation of multi-modal understanding

### Evaluating Vision-Language Models
- [https://www.youtube.com/watch?v=bAcKe2xJdUU](https://www.youtube.com/watch?v=bAcKe2xJdUU) ~1 hour
- Covers: VLM evaluation benchmarks, cross-modal consistency metrics, hallucination in vision models, object grounding and localization

### Audio Processing with Transformers
- [https://www.youtube.com/watch?v=9B3A1uPdB_s](https://www.youtube.com/watch?v=9B3A1uPdB_s) ~35 minutes
- Covers: Audio feature extraction, speech-to-text models, audio classification, multi-modal audio-language models

### Document AI and Intelligent Document Processing
- [https://www.youtube.com/watch?v=WHzgz5-W8TU](https://www.youtube.com/watch?v=WHzgz5-W8TU) ~45 minutes
- Covers: Document parsing and understanding, table extraction and form processing, multi-modal document intelligence, production document AI systems

### Image Captioning and Visual Grounding
- [https://www.youtube.com/watch?v=1h8hAp_HYdU](https://www.youtube.com/watch?v=1h8hAp_HYdU) ~50 minutes
- Covers: Image-to-text generation, visual grounding techniques, attention visualization in VLMs, evaluation metrics for captioning

### Multi-Modal Hallucination Detection
- [https://www.youtube.com/watch?v=K8R3lZ8X5aE](https://www.youtube.com/watch?v=K8R3lZ8X5aE) ~25 minutes
- Covers: Object hallucination in VLMs, cross-modal consistency checking, grounding verification for images, CHAIR metric and variants

### Evaluating Audio Transcription Quality
- [https://www.youtube.com/watch?v=mRB8tbTkkrA](https://www.youtube.com/watch?v=mRB8tbTkkrA) ~20 minutes
- Covers: WER (Word Error Rate) metrics, transcription quality assessment, robustness evaluation for ASR, multi-lingual evaluation challenges

---

<a name="chapter-32---context-relevance"></a>
## Chapter 3.2 - Context Relevance

**Topics:** Retrieval evaluation, context precision/recall, semantic relevance, noise reduction, query understanding

### Dense Passage Retrieval (DPR) for Open-Domain QA
- [https://www.youtube.com/watch?v=NUMg4e74Sz4](https://www.youtube.com/watch?v=NUMg4e74Sz4) ~35 minutes
- Covers: Dense retrieval vs sparse retrieval (BM25), bi-encoder architecture for passage encoding, negative sampling and hard negatives for training, retrieval accuracy metrics (MRR, Recall@k)

### Retrieval-Augmented Generation (RAG) - DeepLearning.AI Course
- [https://www.youtube.com/watch?v=T-D1OfcDW1M](https://www.youtube.com/watch?v=T-D1OfcDW1M) ~1 hour
- Covers: RAG system architecture and components, retrieval quality evaluation (precision, recall, F1), context relevance for generation quality, chunking strategies and embedding techniques

### Evaluating RAG Systems with RAGAS
- [https://www.youtube.com/watch?v=6Q-PH04F_Ow](https://www.youtube.com/watch?v=6Q-PH04F_Ow) ~25 minutes
- Covers: Context precision and context recall metrics, answer relevancy scoring, faithfulness evaluation, automated RAG assessment pipelines

### Semantic Search and Embeddings - Sentence Transformers
- [https://www.youtube.com/watch?v=OATCgQtNX2o](https://www.youtube.com/watch?v=OATCgQtNX2o) ~30 minutes
- Covers: Semantic similarity with sentence embeddings, cosine similarity for relevance scoring, SBERT (Sentence-BERT) architecture, bi-encoders for efficient semantic search

### Advanced RAG Techniques - Hypothetical Document Embeddings (HyDE)
- [https://www.youtube.com/watch?v=ArnMdc-ICCM](https://www.youtube.com/watch?v=ArnMdc-ICCM) ~20 minutes
- Covers: Query transformation for improved retrieval, hypothetical answer generation, retrieval with LLM-generated queries, precision improvement techniques

---

<a name="chapter-33---harmfulness--safety-assessment"></a>
## Chapter 3.3 - Harmfulness & Safety Assessment

**Topics:** Red-teaming, jailbreak detection, toxicity classifiers, bias evaluation, safety benchmarks

### Red Teaming Language Models - Anthropic Research
- [https://www.youtube.com/watch?v=Joz3s6V9fK0](https://www.youtube.com/watch?v=Joz3s6V9fK0) ~35 minutes
- Covers: Systematic red-teaming methodology, adversarial testing of LLMs, safety evaluation frameworks, discovering failure modes and edge cases

### AI Safety and Alignment - Rob Miles
- [https://www.youtube.com/watch?v=pYXy-A4siMw](https://www.youtube.com/watch?v=pYXy-A4siMw) ~20 minutes
- Covers: AI safety fundamentals, alignment challenges, safety evaluation principles, risk assessment frameworks

### Toxicity Detection in Text - Perspective API
- [https://www.youtube.com/watch?v=VoYNwpj7VHE](https://www.youtube.com/watch?v=VoYNwpj7VHE) ~15 minutes
- Covers: Toxicity classification models, Perspective API for content moderation, multi-attribute toxicity scoring, production safety filters

### Bias in AI Systems - Joy Buolamwini (Algorithmic Justice League)
- [https://www.youtube.com/watch?v=QxuyfWoVV98](https://www.youtube.com/watch?v=QxuyfWoVV98) ~18 minutes
- Covers: Algorithmic bias detection, fairness evaluation metrics, demographic bias in AI, social implications of biased systems

### HELM - Holistic Evaluation of Language Models (Stanford)
- [https://www.youtube.com/watch?v=6UuCWdR5iHo](https://www.youtube.com/watch?v=6UuCWdR5iHo) ~45 minutes
- Covers: Comprehensive LLM benchmarking, safety and bias metrics in HELM, toxicity and fairness evaluation, multi-dimensional model assessment

### Constitutional AI and Harmlessness Training
- [https://www.youtube.com/watch?v=KAgKqMqOMl0](https://www.youtube.com/watch?v=KAgKqMqOMl0) ~30 minutes
- Covers: Constitutional AI framework, training models for harmlessness, self-critique and revision mechanisms, reducing harmful outputs through RLHF

### Jailbreaking LLMs and Defense Mechanisms
- [https://www.youtube.com/watch?v=ov7FbEi1g9E](https://www.youtube.com/watch?v=ov7FbEi1g9E) ~25 minutes
- Covers: Prompt injection and jailbreak techniques, adversarial prompt detection, defense strategies against attacks, red-teaming for robustness

### Fairness and Bias Metrics in ML
- [https://www.youtube.com/watch?v=jIXIuYdnyyk](https://www.youtube.com/watch?v=jIXIuYdnyyk) ~12 minutes
- Covers: Demographic parity and equalized odds, bias measurement techniques, fairness-accuracy tradeoffs, production fairness monitoring

### RLHF and Safety Alignment
- [https://www.youtube.com/watch?v=2MBJOuVq380](https://www.youtube.com/watch?v=2MBJOuVq380) ~60 minutes
- Covers: Reinforcement learning from human feedback, safety reward modeling, preference learning for harmlessness, alignment techniques for safe AI

---

<a name="chapter-34---behavioral-consistency"></a>
## Chapter 3.4 - Behavioral Consistency

**Topics:** Persona consistency, style adherence, preference drift, multi-turn coherence, agent state management

### Persona Consistency in Conversational AI
- [https://www.youtube.com/watch?v=3ywZqROGdqk](https://www.youtube.com/watch?v=3ywZqROGdqk) ~50 minutes
- Covers: Persona-grounded dialogue systems, consistency evaluation in conversations, PersonaChat dataset and benchmarks, character maintenance across turns

### Memory and State Management in LangChain Agents
- [https://www.youtube.com/watch?v=SyU60dr4H3Q](https://www.youtube.com/watch?v=SyU60dr4H3Q) ~30 minutes
- Covers: Conversation memory types, state persistence in agents, multi-turn conversation handling, context window management

### LangGraph for Stateful Agent Workflows
- [https://www.youtube.com/watch?v=9BPCV5TYPmg](https://www.youtube.com/watch?v=9BPCV5TYPmg) ~45 minutes
- Covers: Graph-based agent orchestration, state persistence and management, multi-agent coordination, workflow consistency patterns

---

<a name="chapter-35---prompt-optimization-few-shot-learning-and-fine-tuning"></a>
## Chapter 3.5 - Prompt Optimization, Few-Shot Learning, and Fine-Tuning

**Topics:** Prompt engineering, chain-of-thought, few-shot learning, fine-tuning, LoRA, RLHF, reward modeling

### Attention in Transformers - Visual Explanation
- [https://www.youtube.com/watch?v=eMlx5fFNoYc](https://www.youtube.com/watch?v=eMlx5fFNoYc) ~27 minutes
- Covers: Self-attention mechanism foundations, multi-head attention, context processing in transformers, token embeddings and representation learning

### AI Agents - State of Affairs (Andrew Ng & Harrison Chase)
- [https://www.youtube.com/watch?v=4pYzYmSdSH4](https://www.youtube.com/watch?v=4pYzYmSdSH4) ~45 minutes
- Covers: Agentic design patterns (reflection, tool use, planning, multi-agent), agent evaluation and workflows, production agentic systems development, spectrum-based view of agenticness

### State-of-the-Art Prompting for AI Agents
- [https://www.youtube.com/watch?v=DL82mGde6wo](https://www.youtube.com/watch?v=DL82mGde6wo) ~50 minutes
- Covers: Advanced prompting techniques from production experience, metaprompting and evaluation-driven optimization, rubric-based prompt reliability, real-world prompt engineering insights

### RLHF - From Zero to ChatGPT
- [https://youtu.be/2MBJOuVq380](https://youtu.be/2MBJOuVq380) ~60 minutes
- Covers: Reinforcement learning from human feedback fundamentals, three-stage pipeline (pretraining → SFT → reward model → RL), KL divergence and PPO algorithm, reward modeling and preference learning

### LLM Fine-Tuning with QLoRA
- [https://www.youtube.com/watch?v=pCX_3p40Efc](https://www.youtube.com/watch?v=pCX_3p40Efc) ~30 minutes
- Covers: Parameter-efficient fine-tuning with QLoRA, dataset preparation from real data, practical implementation with Hugging Face, conversation chain construction

---

<a name="chapter-36---agent-benchmarking-frameworks"></a>
## Chapter 3.6 - Agent Benchmarking Frameworks

**Topics:** AgentBench, WebArena, GAIA, API-Bank, HumanEval, task-specific evaluation, leaderboards

### AgentBench - Benchmarking LLMs as Agents
- [https://www.youtube.com/watch?v=lREQzTVJbIY](https://www.youtube.com/watch?v=lREQzTVJbIY) ~25 minutes
- Covers: Multi-environment agent evaluation, task diversity in agent benchmarking, performance metrics across domains, comparison of LLMs in agentic settings

### Evaluating Code Generation with HumanEval
- [https://www.youtube.com/watch?v=i8wpLm2j0I0](https://www.youtube.com/watch?v=i8wpLm2j0I0) ~20 minutes
- Covers: HumanEval benchmark for code synthesis, Pass@k metrics for code correctness, functional correctness evaluation, test-based assessment methodology

### LLM Evaluation Fundamentals - DeepLearning.AI
- [https://www.youtube.com/watch?v=gsf_rMZJWZQ](https://www.youtube.com/watch?v=gsf_rMZJWZQ) ~45 minutes
- Covers: Multi-dimensional LLM evaluation, task-specific benchmarks, automated evaluation pipelines, production monitoring strategies

### Evaluating Tool Use in Language Models
- [https://www.youtube.com/watch?v=kqm8pNGX96k](https://www.youtube.com/watch?v=kqm8pNGX96k) ~40 minutes
- Covers: Tool-calling evaluation metrics, API interaction accuracy, function calling benchmarks, Berkeley Function Calling Leaderboard concepts

### Building and Evaluating AI Agents - Andrew Ng
- [https://www.youtube.com/watch?v=sal78ACtGTc](https://www.youtube.com/watch?v=sal78ACtGTc) ~15 minutes
- Covers: Agentic design patterns, agent evaluation strategies, iterative development and testing, performance improvements with agentic workflows

### SWE-bench - Software Engineering Benchmark for Agents
- [https://www.youtube.com/watch?v=8JF-pL2IvKo](https://www.youtube.com/watch?v=8JF-pL2IvKo) ~30 minutes
- Covers: Real-world software engineering tasks, GitHub issue resolution evaluation, code editing and debugging assessment, agent performance on developer workflows

### Multi-Task Evaluation of Language Models
- [https://www.youtube.com/watch?v=gEZrGsRMK4k](https://www.youtube.com/watch?v=gEZrGsRMK4k) ~55 minutes
- Covers: Cross-task generalization, multi-domain evaluation strategies, task sampling and aggregation, benchmark design principles

### HELM - Holistic Evaluation of Language Models
- [https://www.youtube.com/watch?v=6UuCWdR5iHo](https://www.youtube.com/watch?v=6UuCWdR5iHo) ~45 minutes
- Covers: Comprehensive multi-metric evaluation, standardized benchmarking framework, transparency in model assessment, leaderboard methodologies

### Evaluating Conversational AI Agents
- [https://www.youtube.com/watch?v=vN0qKNrJl_Q](https://www.youtube.com/watch?v=vN0qKNrJl_Q) ~35 minutes
- Covers: Dialogue system evaluation, task success metrics, user simulation for testing, production A/B testing

### LangSmith for Agent Evaluation and Monitoring
- [https://www.youtube.com/watch?v=pG_PNcdukUw](https://www.youtube.com/watch?v=pG_PNcdukUw) ~40 minutes
- Covers: Agent tracing and observability, evaluation dataset management, automated testing pipelines, production monitoring and debugging

---

<a name="chapter-37---tool-auditing"></a>
## Chapter 3.7 - Tool Auditing

**Topics:** Tool contracts, JSON schema, validation, hallucination detection, recovery mechanisms, distributed tracing

### Distributed Tracing with OpenTelemetry and Jaeger
- [https://www.youtube.com/watch?v=nwy0I6vdtEE](https://www.youtube.com/watch?v=nwy0I6vdtEE) ~90-120 minutes
- Covers: Post-execution monitoring and distributed tracing, OpenTelemetry instrumentation for multi-step workflows, span transformations and tail-based sampling, correlation of tool invocations

### Trace-Based Testing with OpenTelemetry
- [https://www.youtube.com/watch?v=WMRicNlaehc](https://www.youtube.com/watch?v=WMRicNlaehc) ~20 minutes
- Covers: Post-execution response validation through traces, testing tool invocations in distributed systems, observability-driven testing approaches

### Jaeger V2 and Distributed Tracing
- [https://www.youtube.com/watch?v=lICivVwm-F8](https://www.youtube.com/watch?v=lICivVwm-F8) ~35 minutes
- Covers: Jaeger V2 distributed tracing platform, OpenTelemetry integration, production monitoring patterns, distributed system debugging

### Monadic Error Handling in Python
- [https://www.youtube.com/watch?v=J-HWmoTKhC8](https://www.youtube.com/watch?v=J-HWmoTKhC8) ~25 minutes
- Covers: Advanced error handling patterns, alternatives to traditional exception handling, recovery mechanisms for tool failures, graceful degradation patterns

### LangChain Tutorial Series - Tools and Functions
- [https://www.youtube.com/watch?v=_v_fgW2SkkQ](https://www.youtube.com/watch?v=_v_fgW2SkkQ) Part of 24-video playlist
- Covers: LangChain tools and function calling, tool selection and routing, agent tool invocation patterns, building applications with LangChain tools

---

<a name="chapter-38---action-accuracy"></a>
## Chapter 3.8 - Action Accuracy

**Topics:** Tool selection accuracy, parameter validation, execution paths, trajectory quality, LLM-as-judge

### OpenAI Functions + LangChain - Multi-Tool Agent
- [https://www.youtube.com/watch?v=4KXK6c6TVXQ](https://www.youtube.com/watch?v=4KXK6c6TVXQ) ~20-30 minutes
- Covers: Function calling with LLMs, tool selection and invocation, multi-tool agent architectures, parameter passing to functions

### LLM as a Judge - Evaluation Tutorial
- [https://www.youtube.com/watch?v=kP_aaFnXLmY](https://www.youtube.com/watch?v=kP_aaFnXLmY) ~40 minutes
- Covers: LLM-as-judge evaluation methodology, iterative prompt improvement for evaluation, rubric design for quality assessment, binary classification metrics (precision, recall, F1)

### Multi-Agent AI Systems with AutoGen
- [https://www.youtube.com/watch?v=f5Qr8xUeSH4](https://www.youtube.com/watch?v=f5Qr8xUeSH4) ~40-60 minutes
- Covers: Multi-agent workflows and coordination, agent communication patterns, task decomposition and execution, tool calling in multi-agent contexts

### RAG Components & Troubleshooting with Arize Phoenix
- [https://youtube.com/watch?v=hbQYDpJayFw](https://youtube.com/watch?v=hbQYDpJayFw) ~45-60 minutes
- Covers: RAG system components and troubleshooting, Arize Phoenix observability platform, tracing LLM application runtime, production monitoring and evaluation

---

<a name="chapter-39---reasoning-quality"></a>
## Chapter 3.9 - Reasoning Quality

**Topics:** Chain-of-thought, reasoning evaluation, LLM-as-judge, self-reflection, NLI, formal logic, reasoning metrics

### Andrew Ng on AI Agents and Agentic Reasoning
- [https://www.youtube.com/watch?v=KrRD7r7y7NY](https://www.youtube.com/watch?v=KrRD7r7y7NY) ~45 minutes
- Covers: Four agentic design patterns (Reflection, Tool use, Planning, Multi-agent), reflection pattern for self-evaluation, performance improvements with agentic workflows, evaluation and error analysis in agents

### Andrej Karpathy - Deep Dive into LLMs
- [https://www.youtube.com/watch?v=EWvNQjAaOHw](https://www.youtube.com/watch?v=EWvNQjAaOHw) ~3.5 hours
- Covers: LLM training stack and reasoning capabilities, chain-of-thought reasoning mechanisms, DeepSeek-R1 and reasoning models, RLHF for reasoning improvement

### Attention in Transformers - 3Blue1Brown
- [https://www.youtube.com/watch?v=eMlx5fFNoYc](https://www.youtube.com/watch?v=eMlx5fFNoYc) ~25 minutes
- Covers: Attention mechanism in transformers, context processing and token embeddings, mathematical details of attention

### Large Reasoning Models (LRMs) - IBM Technology
- [https://www.youtube.com/watch?v=enLbj0igyx4](https://www.youtube.com/watch?v=enLbj0igyx4) ~10-15 minutes
- Covers: Difference between LLMs and LRMs, chain-of-thought training with logic puzzles, internal verification and deliberation, reasoning accuracy vs computational cost tradeoffs

### PyReason - Neuro-Symbolic AI
- [https://www.youtube.com/watch?v=8nxuIaTpZzM](https://www.youtube.com/watch?v=8nxuIaTpZzM) ~30-45 minutes
- Covers: Neuro-symbolic AI combining neural and symbolic reasoning, PyReason framework for structured logic, formal logic in AI reasoning, advantages of structured logic over pattern-based reasoning

### SATNet - Constraint Learning and Neural-Symbolic Reasoning
- [https://www.youtube.com/watch?v=IsDpoXExmNA](https://www.youtube.com/watch?v=IsDpoXExmNA) Part of playlist series
- Covers: SATNet architecture for constraint satisfaction, neural-symbolic integration, logical constraint enforcement in neural networks, structured problem solving with differentiable SAT solvers

---

<a name="chapter-310---efficiency-metrics"></a>
## Chapter 3.10 - Efficiency Metrics

**Topics:** Token economics, AgentDiet framework, workflow architecture, model routing, prompt engineering for efficiency

### What's Next for AI Agentic Workflows - Andrew Ng
- [https://www.youtube.com/watch?v=sal78ACtGTc](https://www.youtube.com/watch?v=sal78ACtGTc) ~15 minutes
- Covers: Four agentic design patterns, agentic vs non-agentic workflow comparison, performance benefits of iterative workflows, fast token generation for efficiency, smaller models with agentic patterns outperforming larger models

### Attention in Transformers - 3Blue1Brown
- [https://www.youtube.com/watch?v=eMlx5fFNoYc](https://www.youtube.com/watch?v=eMlx5fFNoYc) ~26 minutes
- Covers: Attention mechanism in transformers, KV pairs in attention computation, efficient context processing

### Visual Guide to Transformer Neural Networks
- [https://www.youtube.com/watch?v=mMa2PmYJlCo](https://www.youtube.com/watch?v=mMa2PmYJlCo) ~15 minutes
- Covers: Multi-head attention visualization, transformer architecture components, computational overhead of attention

### Prompt Engineering Best Practices
- [https://www.youtube.com/watch?v=chAQGTBMXXQ](https://www.youtube.com/watch?v=chAQGTBMXXQ) ~25-30 minutes
- Covers: Efficient prompting techniques, token optimization through prompt design, reducing unnecessary verbosity, few-shot learning efficiency

### Let's Build GPT from Scratch - Andrej Karpathy
- [https://www.youtube.com/watch?v=kCc8FmEb1nY](https://www.youtube.com/watch?v=kCc8FmEb1nY) ~2 hours
- Covers: Building GPT in PyTorch, tokenization and token economics, attention mechanism implementation, training loop and inference optimization, understanding computational costs at code level

### But What is a GPT? - 3Blue1Brown
- [https://www.youtube.com/watch?v=wjZofJX0v4M](https://www.youtube.com/watch?v=wjZofJX0v4M) ~27 minutes
- Covers: GPT architecture and scale, 175 billion weights organization, word embeddings and tokens, computational scale and efficiency considerations
